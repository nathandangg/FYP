{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport os\n\nos.environ['KAGGLE_USERNAME'] = \"bqhuy26\" # username from the json file\nos.environ['KAGGLE_KEY'] = \"f3a6563216ae5ce0488297cb5b2f8d51\" # key from the json fil\n\n# dataset_identifier = 'bqhuy26/gpr2000ae'\ndataset_identifier = 'huybq26/gprmask3720'\n# !kaggle datasets download -d $dataset_identifier\n# !kaggle datasets download -d bqhuy26/gpr2000ae\n!kaggle datasets download -d huybq26/gprmask3720\nzip_file_path = f'/kaggle/working/{dataset_identifier.split(\"/\")[-1]}.zip'\nshutil.unpack_archive(zip_file_path, '/kaggle/working')\nimport os\nos.remove(zip_file_path)\nimage_size = 96\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:33:04.809002Z","iopub.execute_input":"2023-08-18T12:33:04.809562Z","iopub.status.idle":"2023-08-18T12:34:04.006026Z","shell.execute_reply.started":"2023-08-18T12:33:04.809522Z","shell.execute_reply":"2023-08-18T12:34:04.004851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization\n# from tensorflow.keras import layers, models\n\n# import scipy.io as scio\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# from PIL import Image\n# from sklearn import preprocessing\n# from sklearn.preprocessing import scale\n# import tensorflow as tf\n# from tensorflow import keras\n\n# def multi_scale(x, filters, padding=\"same\", strides=1):\n#     c1 = keras.layers.Conv2D(filters, (1,1), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c3 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c5 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c5 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(c5)\n#     c7 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c7 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(c7)\n#     c7 = keras.layers.Conv2D(filters, (3,3), padding=padding, strides=strides, activation=\"relu\")(c7)\n#     c = keras.layers.Concatenate()([c1, c3, c5, c7])\n#     return c\n\n# # def multi_scale(x, filters, padding=\"same\", strides=1):\n# #     c1 = keras.layers.Conv2D(filters, (1, 1), padding=padding, strides=strides, activation=\"relu\")(x)\n# #     c3 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n# #     c5 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n# #     c5 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c5)\n# #     c7 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n# #     c7 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c7)\n# #     c7 = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c7)\n    \n# #     # Combine the features from different branches\n# #     concatenated_features = keras.layers.Concatenate()([c1, c3, c5, c7])\n    \n# #     # Apply additional convolutional layers on the concatenated features\n# #     combined_conv = keras.layers.Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(concatenated_features)\n    \n# #     return combined_conv\n\n\n# def down_block2(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n#     f = int(filters/4)\n#     c = multi_scale(x, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     c = multi_scale(c, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n#     return c, p\n\n# def up_block2(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n#     f = int(filters/4)\n#     us = keras.layers.UpSampling2D((2, 2))(x)\n#     us = keras.layers.Conv2D(filters, (2, 2), padding='same', strides=1, activation=\"relu\")(us)\n#     c = keras.layers.Concatenate()([us, skip])\n#     c = multi_scale(c, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     c = multi_scale(c, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     return c\n\n# def bottleneck2(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n#     f = int(filters/4)\n#     c = multi_scale(x, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     c = multi_scale(c, f)\n#     c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n#     return c\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:34:04.009023Z","iopub.execute_input":"2023-08-18T12:34:04.009421Z","iopub.status.idle":"2023-08-18T12:34:14.107451Z","shell.execute_reply.started":"2023-08-18T12:34:04.009381Z","shell.execute_reply":"2023-08-18T12:34:14.106517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Concatenate, MaxPool2D, UpSampling2D\nimport tensorflow.keras as keras\n\ndef multi_scale(x, filters, padding=\"same\", strides=1):\n    c1 = Conv2D(filters, (1, 1), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c1 = BatchNormalization()(c1)\n    \n    c3 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c3 = BatchNormalization()(c3)\n    \n    c5 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c5 = BatchNormalization()(c5)\n    c5 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c5)\n#     c5 = BatchNormalization()(c5)\n    \n    c7 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(x)\n#     c7 = BatchNormalization()(c7)\n    c7 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c7)\n#     c7 = BatchNormalization()(c7)\n    c7 = Conv2D(filters, (3, 3), padding=padding, strides=strides, activation=\"relu\")(c7)\n    c7 = BatchNormalization()(c7)\n    \n    c = Concatenate()([c1, c3, c5, c7])\n    return c\n\ndef down_block2(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    f = int(filters/4)\n    c = multi_scale(x, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    c = multi_scale(c, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    p = MaxPool2D((2, 2), (2, 2))(c)\n    return c, p\n\ndef up_block2(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    f = int(filters/4)\n    us = UpSampling2D((2, 2))(x)\n    us = Conv2D(filters, (2, 2), padding='same', strides=1, activation=\"relu\")(us)\n    us = BatchNormalization()(us)\n    c = Concatenate()([us, skip])\n    c = multi_scale(c, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    c = multi_scale(c, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    return c\n\ndef bottleneck2(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    f = int(filters/4)\n    c = multi_scale(x, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    c = multi_scale(c, f)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    c = BatchNormalization()(c)\n    return c\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-15T17:04:39.840948Z","iopub.execute_input":"2023-08-15T17:04:39.841731Z","iopub.status.idle":"2023-08-15T17:04:39.848784Z","shell.execute_reply.started":"2023-08-15T17:04:39.841694Z","shell.execute_reply":"2023-08-15T17:04:39.847908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization\nfrom tensorflow.keras import layers, models\n\n# Define the U-Net model\ndef unet(input_shape, num_classes):\n    \n    f0 = 64\n    f = [f0, f0*2, f0*4, f0*8, f0*16]\n    \n    inputs = tf.keras.Input(shape=input_shape)\n\n     #### model_1\n    p0 = inputs\n    c1, p1 = down_block2(p0, f[0])\n    c2, p2 = down_block2(p1, f[1])\n    c3, p3 = down_block2(p2, f[2])\n    c4, p4 = down_block2(p3, f[3])\n    \n    bn = bottleneck2(p4, f[4])\n    \n    u1 = up_block2(bn, c4, f[3])\n    u2 = up_block2(u1, c3, f[2])\n    u3 = up_block2(u2, c2, f[1])\n    u4 = up_block2(u3, c1, f[0])\n    \n    output_1 = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"relu\")(u4)\n    model = tf.keras.Model(inputs, output_1)\n    \n    return model\n#     f0 = 64\n#     f = [f0, f0*2, f0*4, f0*8, f0*16]\n    \n#     inputs = Input(shape=input_shape)\n    \n#     # Encoder\n#     e1, p1 = down_block2(inputs, f[0]) # Modify as needed\n#     e2, p2 = down_block2(p1, f[1]) # Modify as needed\n#     e3, p3 = down_block2(p2, f[2]) # Modify as needed\n#     e4, p4 = down_block2(p3, f[3]) # Modify as needed\n\n#     # Bottleneck\n#     bn = bottleneck2(p4, f[4]) # Modify as needed\n\n#     # Decoder\n#     d1 = up_block2(bn, e4, f[3]) # Modify as needed\n#     d2 = up_block2(d1, e3, f[2]) # Modify as needed\n#     d3 = up_block2(d2, e2, f[1]) # Modify as needed\n#     d4 = up_block2(d3, e1, f[0]) # Modify as needed\n\n#     # Convolutional block for cavity mask\n#     output_cavity = Conv2D(1, (1, 1), padding=\"same\", activation=\"relu\")(d4)\n\n#     # Convolutional block for healthy mask\n#     output_healthy = Conv2D(1, (1, 1),  padding=\"same\", activation=\"relu\")(d4)\n\n#     # Create the model with two outputs\n#     model = Model(inputs=inputs, outputs=[output_healthy, output_cavity])\n    \n#     return model\n\n# Example usage\ninput_shape = (image_size, image_size, 1)  # Define the shape of your input images (e.g., 256x256 RGB images)\nnum_classes = 1  # Define the number of channels in the output image (e.g., 3 for RGB)\n\n# Create the U-Net model\nmodel = unet(input_shape, num_classes)\n\n# Compile the model with an appropriate optimizer and loss function\nmodel.compile(optimizer='adam',  loss='binary_crossentropy' )\n\n# Print the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:39:47.524545Z","iopub.execute_input":"2023-08-18T12:39:47.526230Z","iopub.status.idle":"2023-08-18T12:39:53.964557Z","shell.execute_reply.started":"2023-08-18T12:39:47.526180Z","shell.execute_reply":"2023-08-18T12:39:53.963770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport tensorflow as tf\nimport numpy as np\nimport scipy.io as scio\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import scale\nimport tensorflow as tf\nfrom tensorflow import keras\n\ninput_dir = '/kaggle/working/output'\noutput_dir = '/kaggle/working/mask'\n\ndef load_and_preprocess_input_image(image_path, target_size=(image_size, image_size)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=1)  # Grayscale image with a single channel\n    image = tf.image.convert_image_dtype(image, tf.float32)  # Convert to float32 in the range [0, 1]\n    image = tf.image.resize(image, target_size)\n#     print(\"Input Image Shape:\", image.shape)\n    return image\n\ndef load_and_preprocess_output_image(image_path, target_size=(image_size, image_size)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=1)  # Grayscale image with a single channel\n    image = tf.image.convert_image_dtype(image, tf.float32)  # Convert to float32 in the range [0, 1]\n    image = tf.image.resize(image, target_size)\n#     print(\"Output Image Shape:\", image.shape)\n    return image\n\n# Training\ndef get_lr_metric(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer.lr\n    return lr\n\ndef get_matching_images(input_dir, output_dir, start_index, end_index):\n    input_images = []\n    output_images_trunk = []\n    output_images_cavity = []\n\n    for i in range(start_index, end_index):  # Assuming images from 1 to 1000 are present\n        input_healthy_image_name = f'gray-healthy-{i}.png'\n        input_cavity_image_name = f'gray-cavity-{i}.png'\n        output_healthy_image_name = f'healthy{i}'\n        output_cavity_image_name = f'defect{i}'\n        input_healthy_image_path = os.path.join(input_dir, 'healthy_gray', input_healthy_image_name)\n        input_cavity_image_path = os.path.join(input_dir, 'cavity_gray', input_cavity_image_name)\n        \n        output_healthy_image_trunk_mask = os.path.join(output_dir, 'healthy', output_healthy_image_name+'_combined_mask.png')\n        output_healthy_image_cavity_mask = os.path.join(output_dir, 'healthy', output_healthy_image_name+'_cavity_mask.png')\n        output_cavity_image_trunk_mask = os.path.join(output_dir, 'defect', output_cavity_image_name+'_combined_mask.png')\n        output_cavity_image_cavity_mask = os.path.join(output_dir, 'defect', output_cavity_image_name+'_cavity_mask.png')\n\n\n\n        if os.path.exists(input_healthy_image_path) and os.path.exists(output_healthy_image_trunk_mask):\n            input_image = load_and_preprocess_input_image(input_healthy_image_path)\n            output_image_trunk = load_and_preprocess_output_image(output_healthy_image_trunk_mask)\n            output_image_cavity = load_and_preprocess_output_image(output_healthy_image_cavity_mask)\n            input_images.append(input_image)\n            output_images_trunk.append(output_image_trunk)\n            output_images_cavity.append(output_image_cavity)\n\n#         if os.path.exists(input_cavity_image_path) and os.path.exists(output_cavity_image_path):\n#             input_image = load_and_preprocess_input_image(input_cavity_image_path)\n#             output_image = load_and_preprocess_output_image(output_cavity_image_path)\n#             input_images.append(input_image)\n#             output_images.append(output_image)\n\n        if os.path.exists(input_cavity_image_path) and os.path.exists(output_cavity_image_trunk_mask):\n            input_image = load_and_preprocess_input_image(input_cavity_image_path)\n            output_image_trunk = load_and_preprocess_output_image(output_cavity_image_trunk_mask)\n            output_image_cavity = load_and_preprocess_output_image(output_cavity_image_cavity_mask)\n            input_images.append(input_image)\n            output_images_trunk.append(output_image_trunk)\n            output_images_cavity.append(output_image_cavity)\n\n    return input_images, output_images_trunk, output_images_cavity\nprint(\"Starting getting data ...\")\ninput_images, output_images_trunk, output_images_cavity = get_matching_images(input_dir, output_dir, 20, 1800)\ninput_test, output_test_trunk, output_test_cavity = get_matching_images(input_dir, output_dir, 1, 20)\n\nprint(\"Done getting & preprocessing all paths\")\n\ninput_image_data = np.array(input_images)\noutput_image_data_trunk = np.array(output_images_trunk)\noutput_image_data_cavity = np.array(output_images_cavity)\ninput_test_data = np.array(input_test)\noutput_test_data_trunk = np.array(output_test_trunk)\noutput_test_data_cavity = np.array(output_test_cavity)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:39:54.994894Z","iopub.execute_input":"2023-08-18T12:39:54.995353Z","iopub.status.idle":"2023-08-18T12:43:03.584420Z","shell.execute_reply.started":"2023-08-18T12:39:54.995314Z","shell.execute_reply":"2023-08-18T12:43:03.583326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# i = 3\n# # Show the first input image\n# plt.imshow(input_image_data[i], cmap='gray')\n# plt.title('Input Image')\n# plt.show()\n\n# # Show the first trunk output mask\n# plt.imshow(output_image_data_trunk[i], cmap='gray')\n# plt.title('Trunk Output Mask')\n# plt.show()\n\n# # Show the first cavity output mask\n# plt.imshow(output_image_data_cavity[i], cmap='gray')\n# plt.title('Cavity Output Mask')\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-15T17:17:35.301281Z","iopub.execute_input":"2023-08-15T17:17:35.301703Z","iopub.status.idle":"2023-08-15T17:17:36.213440Z","shell.execute_reply.started":"2023-08-15T17:17:35.301669Z","shell.execute_reply":"2023-08-15T17:17:36.212258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.optimizers import Adam\n\ninput_shape = (image_size, image_size, 1)  # Define the shape of your input images (e.g., 256x256 RGB images)\nnum_classes = 1  # Define the number of channels in the output image (e.g., 3 for RGB)\nbatch_size = 16\nepochs = 100\nalpha = 10\nbeta = 1\n\nmodel_path='/kaggle/working/unet_trained_model-Aug-15.h5'\n\n# Create the U-Net model\nmodel = unet(input_shape, num_classes)\ndef get_lr_metric(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer.lr\n    return lr\n# Compile the model\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True)\nlr_checkpoint = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, min_lr=0)\n# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=MeanSquaredError())\nAdam = keras.optimizers.Adam(lr=1e-2)\nmodel.compile(optimizer=Adam, loss='mse', loss_weights=[alpha, beta], metrics=['mae'])\n\n# Train the model\nhistory = model.fit(input_image_data, output_image_data_cavity, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[model_checkpoint, lr_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T13:13:14.216779Z","iopub.execute_input":"2023-08-18T13:13:14.217192Z","iopub.status.idle":"2023-08-18T13:23:11.502079Z","shell.execute_reply.started":"2023-08-18T13:13:14.217161Z","shell.execute_reply":"2023-08-18T13:23:11.500468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Plot the training loss and validation loss over epochs\nepochs_range = range(1, epochs + 1)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Save the plot as an image\nplt.savefig('/kaggle/working/loss_plot.png')\n\n# Show the plot (optional)\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(model_path)\nmodel.evaluate(x=input_test_data, y=output_test_data_cavity, batch_size=batch_size)\npredicted_output_data_cavity = model.predict(input_test_data)\npath = '/kaggle/working/'\nfor i in range (19):\n    pred1 = predicted_output_data_cavity[i].reshape(image_size, image_size)*255\n    pred1 = Image.fromarray(pred1)\n    pred1.convert('L').save(path + '11_dmrf_pred_%d.png'%(i+1))\n    \n#     pred2 = predicted_output_data_cavity[i].reshape(image_size, image_size)*255\n#     pred2 = Image.fromarray(pred2)\n#     pred2.convert('L').save(path + '9_dmrf_pred_%d.png'%(i+1))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:55:02.232860Z","iopub.execute_input":"2023-08-18T12:55:02.233287Z","iopub.status.idle":"2023-08-18T12:55:06.729965Z","shell.execute_reply.started":"2023-08-18T12:55:02.233245Z","shell.execute_reply":"2023-08-18T12:55:06.728988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}